{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install nltk\n",
    "pip install TextBlob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "from textblob import TextBlob\n",
    "\n",
    "def convert_to_float(price):\n",
    "    return float(price.replace('â‚¹', '').replace(',', ''))\n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s]', ' ', text)\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    text = ' '.join([word for word in text.split() if word not in stop_words])\n",
    "    return text\n",
    "\n",
    "def analyze_sentiment(text):\n",
    "    analysis = TextBlob(text)\n",
    "    if analysis.sentiment.polarity > 0.1:\n",
    "        return 'Positive'\n",
    "    elif analysis.sentiment.polarity < -0.1:\n",
    "        return 'Negative'\n",
    "    else:\n",
    "        return 'Neutral'\n",
    "\n",
    "def preprocess_data(data_file_path):\n",
    "    df = pd.read_csv(data_file_path)\n",
    "    df = df.dropna()\n",
    "    df = df.drop_duplicates()\n",
    "\n",
    "    df['discounted_price'] = df['discounted_price'].apply(convert_to_float)\n",
    "    df['actual_price'] = df['actual_price'].apply(convert_to_float)\n",
    "    df['discount_percentage'] = df['discount_percentage'].str.replace('%', '').astype(float)\n",
    "    df['rating'] = pd.to_numeric(df['rating'].astype(str).str.replace('|', ''), errors='coerce')\n",
    "    df['rating_count'] = df['rating_count'].str.replace(',', '').astype(int)\n",
    "    \n",
    "    df['product_name'] = df['product_name'].apply(clean_text)\n",
    "    df['about_product'] = df['about_product'].apply(clean_text)\n",
    "    df['review_content'] = df['review_content'].apply(clean_text)\n",
    "    df['category_text'] = df['category'].apply(clean_text)\n",
    "    \n",
    "    df['category'] = df['category'].apply(lambda x: x.split('|') if pd.notnull(x) else x)\n",
    "    df['sentiment'] = df['review_content'].apply(analyze_sentiment)\n",
    "\n",
    "    return df\n",
    "\n",
    "filepath = 'amazon.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "def feature_engineering(data):\n",
    "    data['combined_text'] = data['product_name'] + ' ' + data['category_text'] + ' ' + data['about_product'] + ' ' + data['review_content']\n",
    "    vectorizer = TfidfVectorizer(stop_words='english', max_df=0.95, min_df=2, ngram_range=(1, 1))\n",
    "    tfidf_matrix = vectorizer.fit_transform(data['combined_text'])\n",
    "\n",
    "    label_encoder = LabelEncoder()\n",
    "    data['encoded_sentiment'] = label_encoder.fit_transform(data['sentiment'])\n",
    "\n",
    "    cosine_sim = cosine_similarity(tfidf_matrix)\n",
    "    product_user_matrix = data.pivot_table(index='product_id', values='rating', aggfunc='mean').fillna(data['rating'].mean())\n",
    "\n",
    "    return cosine_sim, product_user_matrix\n",
    "\n",
    "def hybrid_recommendation(data, product_id, top_n=10):\n",
    "    idx = data.index[data['product_id'] == product_id][0]\n",
    "\n",
    "    print(idx)\n",
    "    cosine_sim, product_user_matrix = feature_engineering(data)\n",
    "\n",
    "    # Content-based filtering\n",
    "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "    content_recommendations_idx = [i[0] for i in sim_scores[1:top_n+1]]\n",
    "\n",
    "    # Collaborative Filtering\n",
    "    if product_id in product_user_matrix.index:\n",
    "        current_product_rating = product_user_matrix.loc[product_id].values[0]\n",
    "        similar_rating_products = product_user_matrix.iloc[(product_user_matrix['rating']-current_product_rating).abs().argsort()[:top_n]]\n",
    "\n",
    "        # Combine recommendations\n",
    "        collaborative_recommendations_idx = similar_rating_products.index\n",
    "        collaborative_recommendations_idx = [data.index[data['product_id'] == pid].tolist()[0] for pid in collaborative_recommendations_idx]\n",
    "        combined_indices = list(set(content_recommendations_idx + collaborative_recommendations_idx))\n",
    "\n",
    "        recommended_products = data.iloc[combined_indices].copy()\n",
    "        recommended_products = recommended_products[['product_id', 'product_name', 'rating']]\n",
    "\n",
    "        return recommended_products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = preprocess_data(filepath)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sample_pid = 'B07JW9H4J1'\n",
    "hybrid_recommendation(df, sample_pid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_df = df[['user_id', 'user_name', 'review_id', 'review_title', 'review_content']]\n",
    "\n",
    "ratings_df['review_content'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.pivot_table(index='product_id', values='rating', aggfunc='mean').fillna(df['rating'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "products = df.drop(columns=['user_id', 'user_name', 'review_id', 'review_title'])\n",
    "products['combined_text'] = products['product_name'] + ' ' + products['category_text'] + ' ' + products['about_product'] + ' ' + products['review_content']\n",
    "products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "products.to_dict('records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_popular = products.sort_values('rating_count', ascending=False)\n",
    "most_popular[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_popular['category'].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_popular['parent_category'] = most_popular['category'].apply(lambda x: x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_popular.groupby('parent_category').first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_popular[:10].to_dict('records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['product_id'] == df['product_id'][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index[df['product_id'] == sample_pid][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "X1 = vectorizer.fit_transform(products[\"combined_text\"])\n",
    "X1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA \n",
    "pca = PCA(n_components=2)\n",
    "reduced_data = pca.fit_transform(X1.toarray()) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=X1\n",
    "\n",
    "kmeans = KMeans(n_clusters = 10, init = 'k-means++')\n",
    "y_kmeans = kmeans.fit_predict(X)\n",
    "plt.plot(y_kmeans, \".\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "wcss = [] \n",
    "\n",
    "for i in range(1, 15): \n",
    "    kmeans = KMeans(n_clusters = i, init = 'k-means++', random_state = 42)\n",
    "    kmeans.fit(reduced_data) \n",
    "    wcss.append(kmeans.inertia_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(1,15), wcss, 'bx-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_cluster(i):\n",
    "    print(\"Cluster %d:\" % i),\n",
    "    for ind in order_centroids[i, :10]:\n",
    "        print(' %s' % terms[ind])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_k = 15\n",
    "\n",
    "model = KMeans(n_clusters=true_k, init='k-means++', max_iter=100, n_init=1)\n",
    "model.fit(X1)\n",
    "\n",
    "print(\"Top terms per cluster:\")\n",
    "order_centroids = model.cluster_centers_.argsort()[:, ::-1]\n",
    "terms = vectorizer.get_feature_names_out()\n",
    "for i in range(true_k):\n",
    "    print_cluster(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "terms[12200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_recommendations(product):\n",
    "    Y = vectorizer.transform([product])\n",
    "    prediction = model.predict(Y)\n",
    "    print(prediction)\n",
    "    print_cluster(prediction[0])\n",
    "\n",
    "    return prediction[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_recommendations(\"food\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "products['cluster'] = products['product_name'].apply(show_recommendations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "products['cluster']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_in_same_cluster = products[products['cluster'] == 7]\n",
    "product_in_same_cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_in_same_cluster.sort_values('rating_count', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "products[products['product_id'] == 'B09GFPN6TP']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlproj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
